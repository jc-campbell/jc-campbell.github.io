<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://jc-campbell.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jc-campbell.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-13T02:23:01+00:00</updated><id>https://jc-campbell.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">The Normal Inverse Wishart Distribution</title><link href="https://jc-campbell.github.io/blog/2025/invwishart/" rel="alternate" type="text/html" title="The Normal Inverse Wishart Distribution"/><published>2025-02-10T15:59:00+00:00</published><updated>2025-02-10T15:59:00+00:00</updated><id>https://jc-campbell.github.io/blog/2025/invwishart</id><content type="html" xml:base="https://jc-campbell.github.io/blog/2025/invwishart/"><![CDATA[<p>Inverse Wishart?</p>]]></content><author><name></name></author><category term="MATH415,"/><category term="financial-economics"/><category term="stock-market,"/><category term="statistics,"/><category term="statistical-modelling,"/><category term="statistical-distributions"/><summary type="html"><![CDATA[a weird distribution for weird people]]></summary></entry><entry><title type="html">Modelling Stock Market Returns</title><link href="https://jc-campbell.github.io/blog/2025/stockreturnmodelling/" rel="alternate" type="text/html" title="Modelling Stock Market Returns"/><published>2025-02-08T15:59:00+00:00</published><updated>2025-02-08T15:59:00+00:00</updated><id>https://jc-campbell.github.io/blog/2025/stockreturnmodelling</id><content type="html" xml:base="https://jc-campbell.github.io/blog/2025/stockreturnmodelling/"><![CDATA[<p>For the past few weeks, I’ve been working on a <a href="/projects/financial_econ">Portfolio Optimization Showcase</a> as an exercise showing my progress in MATH 415: Math Financial Economics. In order to to solve the problem posed in Modern Portfolio Theory, it is first necessary to estimate the expected prices of the set of market assets available for inclusion in a portfolio. In this post, I will expound the model I used in the showcase, which follows the model in Attilio Meucci’s <em>Risk and Asset Allocation</em><sup id="fnref:fn"><a href="#fn:fn" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, and then show how to implement it in Python.</p> <h2 id="model-specification"><strong>Model Specification</strong></h2> <p>We model the vector of asset returns as a multivariate normal distribution:</p> \[\begin{equation}r \sim \mathcal{N}(\mu, \Sigma)\end{equation}\] <p>where:</p> <ul> <li>$\mu$ is the $N \times 1$ vector of expected returns</li> <li>$\Sigma$ is the $N \times N$ covariance matrix of returns</li> </ul> <h3 id="priors"><strong>Priors</strong></h3> <p>We model the prior distribution for $\mu$ and $\Sigma$ using a <a href="https://en.wikipedia.org/wiki/Normal-inverse-Wishart_distribution">normal-inverse-Wishart distribution</a>, which is a natural fit because of the way it plays nicely with the inference step.</p> \[\mu | \Sigma \sim \mathcal{N}(\mu_0, \Sigma / \kappa_0) \hspace{16pt} \Sigma \sim \text{Inv-Wishart}(\Psi_0, v_0)\] <p>where</p> <ul> <li>$\mu_0 \in \mathbb{R}^N$ is the prior expected return vector</li> <li>$\kappa_0 \in \mathbb{R}^+$ is the investor’s confidence in the prior view on the mean</li> <li>$v_0$ is the degrees of freedom</li> <li>$\Psi_0$ is the scale matrix, a prior on $\Sigma^{-1}$.</li> </ul> <p>If you’re like me, reading all that gave you a headache. Before embarking on this project, I had never heard of the Inverse Wishart distribution, but it’s a fascinating topic that I cover in <a href="/blog/2025/invwishart">this post</a>.</p> <h3 id="bayesian-inference"><strong>Bayesian Inference</strong></h3> <p>The Normal-Inverse-Wishart distribution is conjugate to the multivariate normal liklihood, so the posterior is also Normal-Inverse-Wishart with updated hyperparameters:</p> <ul> <li>$\kappa_n = \kappa_0 + T$</li> <li>$\mathbf{\mu}_n = \frac{\kappa_0 \mathbf{\mu}_0 + T \bar{\mathbf{r}}}{\kappa_0 + T}$ ($\bar{\mathbf{r}}$ being the vector of sample means)</li> <li>$\nu_n = \nu_0 + T$</li> <li>$\Psi_n = \Psi_0 + S +c \frac{\kappa_0 T}{\kappa_0 + T}(\bar{\mathbf{r}} - \mu_0)(\bar{\mathbf{r}} - \mu_0)^T$ ($S$ being the covariance matrix of the sampled returns)</li> </ul> <p>In order to use the new hyperparameters to generate a posterior distribution, we need to sample from the multivariate t-distribution formed by integrating out $\mu$ and $\Sigma$:</p> \[\mathbf{r}_{T+1} | \{\mathbf{r}_{t}\}_{t=1}^T \sim t_{\underbrace{\nu_n - d + 1}_{\text{dof}}}\left(\mu_n, \underbrace{\frac{\kappa_n + 1}{\kappa_n (\nu_n - d + 1)}\Psi_n}_{\text{Predictive }\Sigma}\right)\] <h2 id="implementation-in-python"><strong>Implementation in Python</strong></h2> <p>We’ll use Python for this project, so let’s start by importing libraries:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">yfinance</span> <span class="k">as</span> <span class="n">yf</span> <span class="c1"># To get stock price history
</span><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">scipy.stats</span> <span class="k">as</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div></div> <p>We’ll pull the history of a set of 30 tickers from the NYSE which are, for demonstration purposes, divided into three groups: Financial, Utilities, and Miscellaneous.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_days</span> <span class="o">=</span> <span class="mi">100</span>   <span class="c1"># Feel free to adjust based on your confidence the yahoo won't rate limit you
</span><span class="n">tickers</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># Group 1: Financials (tightly correlated)
</span>    <span class="sh">"</span><span class="s">JPM</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">BAC</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">WFC</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">C</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">GS</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">MS</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">AXP</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">PNC</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">USB</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SCHW</span><span class="sh">"</span><span class="p">,</span>
    <span class="c1"># Group 2: Utilities (tightly correlated but hopefully somewhat uncorrelated with Group 1)
</span>    <span class="sh">"</span><span class="s">DUK</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">SO</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">EXC</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">D</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NEE</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">EIX</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">AEP</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">XEL</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">PEG</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">WEC</span><span class="sh">"</span><span class="p">,</span>
    <span class="c1"># Group 3: Diverse, relatively uncorrelated assets
</span>    <span class="sh">"</span><span class="s">IBM</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">JNJ</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">PG</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">GE</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">XOM</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">AAPL</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">UPS</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">AMT</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">T</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NKE</span><span class="sh">"</span>
<span class="p">]</span>


<span class="c1"># Fetch the historical data for the stocks from Yahoo finance
</span><span class="n">data</span> <span class="o">=</span> <span class="n">yf</span><span class="p">.</span><span class="nf">download</span><span class="p">(</span><span class="n">tickers</span><span class="p">,</span>
                   <span class="n">period</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">n_days</span><span class="si">}</span><span class="s">d</span><span class="sh">'</span><span class="p">,</span>   <span class="c1"># Number of days to fetch
</span>                   <span class="n">interval</span><span class="o">=</span><span class="sh">'</span><span class="s">1d</span><span class="sh">'</span>   <span class="c1"># We will use daily returns, feel free to adjust
</span>                    <span class="p">)</span>

<span class="c1"># Extract the DataFrame with daily closing prices
</span><span class="n">closing_prices</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">Close</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># Get Logged Returns
</span><span class="n">log_returns</span> <span class="o">=</span> <span class="n">closing_prices</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">).</span><span class="nf">diff</span><span class="p">().</span><span class="nf">dropna</span><span class="p">()</span>

<span class="c1"># Print a sample to console to check that all data are available
</span><span class="n">log_returns</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:]</span>
</code></pre></div></div> <p>You should now see a table with the five log returns per stock.</p> <h3 id="define-priors"><strong>Define Priors</strong></h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">d</span> <span class="o">=</span> <span class="n">log_returns</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Number of stocks
</span>
<span class="n">mu_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="c1"># Prior expected returns
</span><span class="n">kappa_0</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="c1"># Prior scaling factor
</span><span class="n">nu_0</span> <span class="o">=</span> <span class="n">d</span> <span class="o">+</span> <span class="mi">2</span> <span class="c1"># Prior DOF
</span><span class="n">Psi_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="c1"># Prior inverse covariance matrix (sort of)
</span></code></pre></div></div> <h3 id="inference-step"><strong>Inference Step</strong></h3> <p>Using the formulas in the <a href="#bayesian-inference">Bayesian Inference</a> section, we update the hyperparameters:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">T</span> <span class="o">=</span> <span class="n">log_returns</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Number of time periods
</span>
<span class="n">r_mean</span> <span class="o">=</span> <span class="n">log_returns</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">to_numpy</span><span class="p">()</span>  <span class="c1"># Sample mean
</span><span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">log_returns</span> <span class="o">-</span> <span class="n">r_mean</span><span class="p">).</span><span class="nf">to_numpy</span><span class="p">()</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="c1"># Sample covariance
</span>
<span class="n">kappa_n</span> <span class="o">=</span> <span class="n">kappa_0</span> <span class="o">+</span> <span class="n">T</span>
<span class="n">mu_n</span> <span class="o">=</span> <span class="p">(</span><span class="n">kappa_0</span> <span class="o">*</span> <span class="n">mu_0</span> <span class="o">+</span> <span class="n">T</span> <span class="o">*</span> <span class="n">r_mean</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">kappa_0</span> <span class="o">+</span> <span class="n">T</span><span class="p">)</span>
<span class="n">nu_n</span> <span class="o">=</span> <span class="n">nu_0</span> <span class="o">+</span> <span class="n">T</span>
<span class="n">Psi_n</span> <span class="o">=</span> <span class="n">Psi_0</span> <span class="o">+</span> <span class="n">S</span> <span class="o">+</span> <span class="p">((</span><span class="n">kappa_0</span> <span class="o">*</span> <span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">kappa_0</span> <span class="o">+</span> <span class="n">T</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">r_mean</span> <span class="o">-</span> <span class="n">mu_0</span><span class="p">)</span> <span class="o">@</span> <span class="p">(</span><span class="n">r_mean</span> <span class="o">-</span> <span class="n">mu_0</span><span class="p">).</span><span class="n">T</span>
</code></pre></div></div> <h3 id="posterior-distribution"><strong>Posterior Distribution</strong></h3> <p>All that’s left to do now is to build the multivariate t-distribution that represents our prediction for the distribution of market log-returns.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">nu_n</span> <span class="o">-</span> <span class="n">d</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># The degrees of freedom
</span><span class="n">predictive_cov</span> <span class="o">=</span> <span class="p">((</span><span class="n">kappa_n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">kappa_n</span> <span class="o">*</span> <span class="n">df</span><span class="p">))</span> <span class="o">*</span> \
    <span class="n">Psi_n</span>  <span class="c1"># The predictive covariance matrix
</span>
<span class="n">predictive_dist</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="nf">multivariate_t</span><span class="p">(</span>
  <span class="n">loc</span><span class="o">=</span><span class="n">mu_n</span><span class="p">,</span> 
  <span class="n">shape</span><span class="o">=</span><span class="n">predictive_cov</span><span class="p">,</span> 
  <span class="n">df</span><span class="o">=</span><span class="n">df</span>
<span class="p">)</span>
</code></pre></div></div> <p>To visualize this distribution, I built this scatterplot with plotly. It plots the expected volatility (standard deviation) of each stock on the x-axis against expected returns on the y-axis. Mouse over a point, and the other points will change color to represent the level of correlation with your selected stock.</p> <div style="aspect-ratio: 16/9"> <iframe src="/assets/plotly/stockreturnmodelling_cov_scatterplot.html" frameborder="0" scrolling="no" height="100%" width="100%"></iframe> </div> <h2 id="conclusion"><strong>Conclusion</strong></h2> <p>The stock market is a noisy data generating process, and predicting is difficult (read: impossible). This model is useful, as it will allow us to continue into the portfolio optimization step, but it ultimately lacks clarity. A better model likely involves exogenous factors and the introduction of time series dependence. Perhaps, someday soon, I’ll built such a model. For now, however, please feel free to read the next chaper of this series, where I explore <a href="/projects/financial_econ">Modern Portfolio Optimization</a>.</p> <hr/> <h2 id="references"><strong>References</strong></h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:fn"> <p><a href="https://link.springer.com/book/10.1007/978-3-540-27904-4">Attilio Meucci, Risk and Asset Allocation, 1st ed. 2005. Corr. 3rd printing 2009 edition (Berlin ; New York: Springer, 2009)</a>. <a href="#fnref:fn" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="MATH415,"/><category term="financial-economics"/><category term="stock-market,"/><category term="statistics,"/><category term="statistical-modelling"/><summary type="html"><![CDATA[a statistial model of asset prices using a heirachical Bayesian model]]></summary></entry></feed>